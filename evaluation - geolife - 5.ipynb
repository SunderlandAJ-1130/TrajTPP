{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzengav/.conda/envs/tpp_safety/lib/python3.9/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import dpp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as td\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import top_k_accuracy_score, f1_score\n",
    "from dpp.eval_funcs import *\n",
    "\n",
    "# matplotlib.rcParams['text.usetex'] = True\n",
    "# plt.style.use(['science', 'ieee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "time_threshold = 15\n",
    "trip_threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correct_total_prediction(logits, true_y):\n",
    "\n",
    "    # top_ = torch.eq(torch.argmax(logits, dim=-1), true_y).sum().cpu().numpy()\n",
    "    top1 = []\n",
    "    result_ls = []\n",
    "    for k in [1, 3, 5, 10]:\n",
    "        if logits.shape[-1] < k:\n",
    "            k = logits.shape[-1]\n",
    "        prediction = torch.topk(logits, k=k, dim=-1).indices\n",
    "        # f1 score\n",
    "        if k == 1:\n",
    "            top1 = torch.squeeze(prediction).cpu()\n",
    "            # f1 = f1_score(true_y.cpu(), prediction.cpu(), average=\"weighted\")\n",
    "\n",
    "        top_k = torch.eq(true_y[:, None], prediction).any(dim=1).sum().cpu().numpy()\n",
    "        # top_k = np.sum([curr_y in pred for pred, curr_y in zip(prediction, true_y)])\n",
    "        result_ls.append(top_k)\n",
    "    # f1 score\n",
    "    # result_ls.append(f1)\n",
    "    # rr\n",
    "    result_ls.append(get_mrr(logits, true_y))\n",
    "    # ndcg\n",
    "    result_ls.append(get_ndcg(logits, true_y))\n",
    "\n",
    "    # total\n",
    "    result_ls.append(true_y.shape[0])\n",
    "\n",
    "    return np.array(result_ls, dtype=np.float32), true_y.cpu(), top1\n",
    "\n",
    "\n",
    "def get_mrr(prediction, targets):\n",
    "    \"\"\"\n",
    "    Calculates the MRR score for the given predictions and targets.\n",
    "\n",
    "    Args:\n",
    "        prediction (Bxk): torch.LongTensor. the softmax output of the model.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "\n",
    "    Returns:\n",
    "        the sum rr score\n",
    "    \"\"\"\n",
    "    index = torch.argsort(prediction, dim=-1, descending=True)\n",
    "    hits = (targets.unsqueeze(-1).expand_as(index) == index).nonzero()\n",
    "    ranks = (hits[:, -1] + 1).float()\n",
    "    rranks = torch.reciprocal(ranks)\n",
    "\n",
    "    return torch.sum(rranks).cpu().numpy()\n",
    "\n",
    "\n",
    "def get_ndcg(prediction, targets, k=10):\n",
    "    \"\"\"\n",
    "    Calculates the NDCG score for the given predictions and targets.\n",
    "\n",
    "    Args:\n",
    "        prediction (Bxk): torch.LongTensor. the softmax output of the model.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "\n",
    "    Returns:\n",
    "        the sum rr score\n",
    "    \"\"\"\n",
    "    index = torch.argsort(prediction, dim=-1, descending=True)\n",
    "    hits = (targets.unsqueeze(-1).expand_as(index) == index).nonzero()\n",
    "    ranks = (hits[:, -1] + 1).float().cpu().numpy()\n",
    "\n",
    "    not_considered_idx = ranks > k\n",
    "    ndcg = 1 / np.log2(ranks + 1)\n",
    "    ndcg[not_considered_idx] = 0\n",
    "\n",
    "    return np.sum(ndcg)\n",
    "\n",
    "\n",
    "def get_performance_dict(return_dict):\n",
    "    perf = {\n",
    "        \"correct@1\": return_dict[\"correct@1\"],\n",
    "        \"correct@3\": return_dict[\"correct@3\"],\n",
    "        \"correct@5\": return_dict[\"correct@5\"],\n",
    "        \"correct@10\": return_dict[\"correct@10\"],\n",
    "        \"rr\": return_dict[\"rr\"],\n",
    "        \"ndcg\": return_dict[\"ndcg\"],\n",
    "        \"f1\": return_dict[\"f1\"],\n",
    "        \"total\": return_dict[\"total\"],\n",
    "    }\n",
    "\n",
    "    perf[\"acc@1\"] = perf[\"correct@1\"] / perf[\"total\"] * 100\n",
    "    perf[\"acc@5\"] = perf[\"correct@5\"] / perf[\"total\"] * 100\n",
    "    perf[\"acc@10\"] = perf[\"correct@10\"] / perf[\"total\"] * 100\n",
    "    perf[\"mrr\"] = perf[\"rr\"] / perf[\"total\"] * 100\n",
    "    perf[\"ndcg\"] = perf[\"ndcg\"] / perf[\"total\"] * 100\n",
    "\n",
    "    return perf\n",
    "\n",
    "\n",
    "def get_top_k_values(arr, k):\n",
    "    # 对向量进行排序并获取索引\n",
    "    sorted_indices = np.argsort(arr)\n",
    "    # 获取最大的K个值的索引\n",
    "    top_indices = sorted_indices[-k:]\n",
    "    # 获取最大的K个值\n",
    "    top_values = arr[top_indices]\n",
    "    return top_values, top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_1 = []\n",
    "ACC_5 = []\n",
    "ACC_10 = []\n",
    "F1s = []\n",
    "MRRs = []\n",
    "NDCGs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['log-2024-04-08-16-29-01', 'log-2024-04-08-16-34-44',\n",
       "       'log-2024-04-08-16-40-35', 'log-2024-04-08-16-46-57',\n",
       "       'log-2024-04-08-16-52-53'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "mode_ = 'TrajTPP'\n",
    "folder_path = f'./log/{mode_}-15-5/'\n",
    "file_names = os.listdir(folder_path)\n",
    "file_names = np.sort(file_names)\n",
    "file_names = file_names[:5]\n",
    "\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_name = 'LogNormMix' # other: ['RMTPP', 'FullyNeuralNet', 'Exponential', 'SOSPolynomial', 'DeepSigmoidalFlow']\n",
    "batch_size = 1024\n",
    "\n",
    "## General data config\n",
    "dataset_name = './dataset/geolife'\n",
    "dataset_name = f'{dataset_name}-{time_threshold}-{trip_threshold}/'\n",
    "\n",
    "d_train, num_drivers = dpp.data.load_dataset(f'{dataset_name}train', device=device)\n",
    "d_val, _ = dpp.data.load_dataset(f'{dataset_name}val', device=device)\n",
    "d_test, _ = dpp.data.load_dataset(f'{dataset_name}test', device=device)\n",
    "\n",
    "# Calculate mean and std of the input inter-event times and normalize only input\n",
    "mean_in_train, std_in_train = d_train.get_mean_std_in()\n",
    "std_out_train = 1.0\n",
    "d_train.normalize(mean_in_train, std_in_train, std_out_train)\n",
    "d_val.normalize(mean_in_train, std_in_train, std_out_train)\n",
    "d_test.normalize(mean_in_train, std_in_train, std_out_train)\n",
    "\n",
    "# Break down long train sequences for faster batch traning and create torch DataLoaders\n",
    "d_train.break_down_long_sequences(128)\n",
    "collate = dpp.data.collate\n",
    "dl_train = torch.utils.data.DataLoader(d_train, batch_size=batch_size, shuffle=True, collate_fn=collate, generator=torch.Generator(device=device))\n",
    "dl_val = torch.utils.data.DataLoader(d_val, batch_size=1, shuffle=False, collate_fn=collate, generator=torch.Generator(device=device))\n",
    "dl_test = torch.utils.data.DataLoader(d_test, batch_size=1, shuffle=False, collate_fn=collate, generator=torch.Generator(device=device))\n",
    "\n",
    "# Set the parameters for affine normalization layer depending on the decoder (see Appendix D.3 in the paper)\n",
    "if decoder_name in {'RMTPP', 'FullyNeuralNet', 'Exponential'}:\n",
    "    _, std_out_train = d_train.get_mean_std_out()\n",
    "    mean_out_train = 0.0\n",
    "else:\n",
    "    mean_out_train, std_out_train = d_train.get_log_mean_std_out()\n",
    "    \n",
    "upper_inter_time = 1440\n",
    "lower_inter_time = 1e-2\n",
    "upper_boundary = (np.log(upper_inter_time)-mean_in_train) / std_in_train\n",
    "lower_boundary = (np.log(lower_inter_time)-mean_in_train) / std_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.334\n",
      "acc@5: 0.574\n",
      "acc@10: 0.613\n",
      "f1_score: 0.256\n",
      "acc@1: 0.337\n",
      "acc@5: 0.587\n",
      "acc@10: 0.629\n",
      "f1_score: 0.245\n",
      "acc@1: 0.347\n",
      "acc@5: 0.584\n",
      "acc@10: 0.625\n",
      "f1_score: 0.246\n",
      "acc@1: 0.343\n",
      "acc@5: 0.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@10: 0.635\n",
      "f1_score: 0.238\n",
      "acc@1: 0.330\n",
      "acc@5: 0.581\n",
      "acc@10: 0.606\n",
      "f1_score: 0.231\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(file_names)):\n",
    "    log_name = file_names[i]\n",
    "    mode = f'{mode_}-{time_threshold}-{trip_threshold}'\n",
    "\n",
    "    seed = 3407\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    with open(f'./log/{mode}/{log_name}/evaluation_tpp.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)    \n",
    "        \n",
    "    y_mark = data['y_mark']\n",
    "    y_mark_hat = data['y_mark_hat']\n",
    "    y_mark_hat_prob = data['y_mark_hat_prob']\n",
    "    \n",
    "    true_ls = []\n",
    "    top1_ls = []\n",
    "    time_ls = []\n",
    "\n",
    "    result_arr = np.array([0, 0, 0, 0, 0, 0, 0], dtype=np.float32)\n",
    "    result_dict = {}\n",
    "    count_user = {}\n",
    "    for i in range(1, num_drivers):\n",
    "        result_dict[i] = np.array([0, 0, 0, 0, 0, 0, 0], dtype=np.float32)\n",
    "        count_user[i] = 0\n",
    "        \n",
    "    logits = torch.tensor(y_mark_hat_prob)\n",
    "    y = torch.tensor(y_mark)\n",
    "\n",
    "    batch_result_arr, batch_true, batch_top1 = calculate_correct_total_prediction(logits, y)\n",
    "    result_arr += batch_result_arr\n",
    "    true_ls.extend(batch_true.numpy())\n",
    "    top1_ls.extend(batch_top1.numpy())\n",
    "    f1 = f1_score(true_ls, top1_ls, average=\"weighted\")\n",
    "        \n",
    "    return_dict = {\n",
    "        \"correct@1\": result_arr[0],\n",
    "        \"correct@3\": result_arr[1],\n",
    "        \"correct@5\": result_arr[2],\n",
    "        \"correct@10\": result_arr[3],\n",
    "        \"f1\": f1,\n",
    "        \"rr\": result_arr[4],\n",
    "        \"ndcg\": result_arr[5],\n",
    "        \"total\": result_arr[6]\n",
    "        }\n",
    "    result_arr_user = result_dict\n",
    "\n",
    "    performance = get_performance_dict(return_dict)\n",
    "    performance[\"type\"] = \"test\"\n",
    "    # print(performance)\n",
    "\n",
    "    result_user_df = pd.DataFrame(result_arr_user).T\n",
    "    result_user_df.columns = [\n",
    "        \"correct@1\",\n",
    "        \"correct@3\",\n",
    "        \"correct@5\",\n",
    "        \"correct@10\",\n",
    "        \"rr\",\n",
    "        \"ndcg\",\n",
    "        \"total\",\n",
    "    ]\n",
    "    result_user_df.index.name = \"user\"\n",
    "    \n",
    "    for i in [1, 5, 10]:\n",
    "        acc_ = top_k_accuracy_score(\n",
    "            y_true=y_mark,\n",
    "            y_score=y_mark_hat_prob,\n",
    "            labels=np.arange(1187),\n",
    "            k=i\n",
    "        )\n",
    "        \n",
    "        print(f'acc@{i}: {acc_:.3f}')\n",
    "\n",
    "    f1_score_ = f1_score(y_true=y_mark, y_pred=y_mark_hat, average='weighted')\n",
    "    print(f'f1_score: {f1_score_:.3f}')\n",
    "\n",
    "    result = {}\n",
    "    top_k_list = [1, 5, 10]\n",
    "\n",
    "    for topk in top_k_list:\n",
    "        intermediate_result = {}\n",
    "        hit, rank, dcg = top_k(loc_pred=y_mark_hat_prob, loc_true=y_mark, topk=topk)\n",
    "\n",
    "        intermediate_result['hit'] = hit\n",
    "        intermediate_result['rank'] = rank\n",
    "        intermediate_result['dcg'] = dcg\n",
    "        intermediate_result['total'] = y_mark.shape[0]\n",
    "\n",
    "        precision_key = 'Precision@{}'.format(topk)\n",
    "        precision = intermediate_result['hit'] / (\n",
    "                intermediate_result['total'] * topk)\n",
    "        result[precision_key] = precision\n",
    "\n",
    "        # recall is used to valid in the trainning, so must exit\n",
    "        recall_key = 'Recall@{}'.format(topk)\n",
    "        recall = intermediate_result['hit'] \\\n",
    "                    / intermediate_result['total']\n",
    "        result[recall_key] = recall\n",
    "        f1_key = 'F1@{}'.format(topk)\n",
    "        if precision + recall == 0:\n",
    "            result[f1_key] = 0.0\n",
    "        else:\n",
    "            result[f1_key] = (2 * precision * recall) / (precision +\n",
    "                                                                recall)\n",
    "            \n",
    "        mrr_key = 'MRR@{}'.format(topk)\n",
    "        result[mrr_key] = intermediate_result['rank'] \\\n",
    "                                / intermediate_result['total']\n",
    "        map_key = 'MAP@{}'.format(topk)\n",
    "        result[map_key] = intermediate_result['rank'] \\\n",
    "                                / intermediate_result['total']\n",
    "        ndcg_key = 'NDCG@{}'.format(topk)\n",
    "        result[ndcg_key] = intermediate_result['dcg'] \\\n",
    "                                / intermediate_result['total']\n",
    "\n",
    "    df = np.zeros(shape=(len(top_k_list), int(len(result.keys())/len(top_k_list))))\n",
    "\n",
    "    for (i, key) in enumerate(result.keys()):\n",
    "        j = i // int(len(result.keys())/len(top_k_list))\n",
    "        k = i % int(len(result.keys())/len(top_k_list))\n",
    "\n",
    "        df[j, k] = result[key]\n",
    "\n",
    "    df = pd.DataFrame(df, columns=['Precision', 'Recall', 'F1', 'MRR', 'MAP', 'NDCG'], index=top_k_list)\n",
    "\n",
    "    ACC_1.append(result['Recall@1'])\n",
    "    ACC_5.append(result['Recall@5'])\n",
    "    ACC_10.append(result['Recall@10'])\n",
    "    F1s.append(f1_score_)\n",
    "    MRRs.append(result['MRR@10'])\n",
    "    NDCGs.append(result['NDCG@10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_1 = np.array(ACC_1)\n",
    "ACC_5 = np.array(ACC_5)\n",
    "ACC_10 = np.array(ACC_10)\n",
    "F1s = np.array(F1s)\n",
    "MRRs = np.array(MRRs)\n",
    "NDCGs = np.array(NDCGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------ACC_1:----------\n",
      "33.84793292859208 0.6239223340949963\n"
     ]
    }
   ],
   "source": [
    "print('----------ACC_1:----------')\n",
    "print(ACC_1.mean()*100, ACC_1.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------ACC_5:----------\n",
      "58.32899681989014 0.5474932900267485\n"
     ]
    }
   ],
   "source": [
    "print('----------ACC_5:----------')\n",
    "print(ACC_5.mean()*100, ACC_5.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------ACC_10:----------\n",
      "62.1740387395201 1.0848951706581522\n"
     ]
    }
   ],
   "source": [
    "print('----------ACC_10:----------')\n",
    "print(ACC_10.mean()*100, ACC_10.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------F1s:----------\n",
      "24.310745167745797 0.8364300844545187\n"
     ]
    }
   ],
   "source": [
    "print('----------F1s:----------')\n",
    "print(F1s.mean()*100, F1s.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------MRRs:----------\n",
      "44.32104195634105 0.6580350245919784\n"
     ]
    }
   ],
   "source": [
    "print('----------MRRs:----------')\n",
    "print(MRRs.mean()*100, MRRs.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------NDCGs:----------\n",
      "48.71933044542166 0.7178390328452898\n"
     ]
    }
   ],
   "source": [
    "print('----------NDCGs:----------')\n",
    "print(NDCGs.mean()*100, NDCGs.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3cf19d595f3d2e6e88f013f452f888e31767c95c166a874850dd2a60d3524b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
